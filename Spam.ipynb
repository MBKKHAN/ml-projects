{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6143903-e7ff-43b1-9634-29cbf55f92dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in g:\\temp\\test\\stat-env\\lib\\site-packages (4.4.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in g:\\temp\\test\\stat-env\\lib\\site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.7.0 in g:\\temp\\test\\stat-env\\lib\\site-packages (from gensim) (1.15.3)\n",
      "Requirement already satisfied: smart_open>=1.8.1 in g:\\temp\\test\\stat-env\\lib\\site-packages (from gensim) (7.5.0)\n",
      "Requirement already satisfied: wrapt in g:\\temp\\test\\stat-env\\lib\\site-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c4adf2c-e450-4e4c-9532-28394c30214a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from gensim.parsing.porter import PorterStemmer\n",
    "from gensim.utils import tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2d25043-1c12-410c-af59-26a0dc3e1856",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam = [\n",
    "    \"To use your credit, click the new WAP link in the next years txt message or click here\", \n",
    "    \"Thanks for your subscription to New Ringtone UK your new mobile will be charged £5/month Please confirm annoncement by replying\", \n",
    "    \"As a valued customer, I am pleased to advise you that following recent delivery waiting review of your Mob No. you are awarded with. Call us to review.\", \n",
    "    \"Please call our new customer service representative on\", \n",
    "    \"We are trying to contact you. Last weekends customer draw shows that you won a £1000 prize GUARANTEED. Calling years\", \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5eee3c94-c1bc-4c9a-b2c1-b3ee89641c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_test=[\"Customer service annoncement. You have a New Years delivery waiting for you. click\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9da5fb61-5c85-41c8-a666-4ca1b097f079",
   "metadata": {},
   "outputs": [],
   "source": [
    "non=[ \"I don't think he goes to usf, he lives around here though\", \n",
    "    \"New car and house for my parents. i have only new job in hand\", \n",
    "    \"Great escape. I fancy the bridge but needs her lager. See you tomorrow\", \n",
    "    \"Tired. I haven't slept well the past few nights.\",\n",
    "    \"Too late. I said i have the website. I didn't i have or dont have the slippers\", \n",
    "    \"I might come by tonight then if my class lets out early\", \n",
    "    \"Jos ask if u wana meet up?\", \n",
    "    \"That would be great. We'll be at the Guild. We can try meeting with the customer on Bristol road or somewhere\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ed76fee-c729-4d0c-9c6a-c98d0b61a381",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_test2=[\"That would be great. We'll be at the Guild. We can try meeting with the customer on Bristol road or somewhere\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab20c741-5798-441d-b68a-b9ef5c2df28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Sentence:  Tired. I haven't slept well the past few nights.\n",
      "Removed Words:  Tired. I haven't slept past nights.\n",
      "Stemmed Sentence:  tired. i haven't slept past nights.\n",
      "Tokenize Sentence:  ['tired', 'i', 'haven', 't', 'slept', 'past', 'nights']\n"
     ]
    }
   ],
   "source": [
    "test=non[3]\n",
    "print(\"Test Sentence: \",test)\n",
    "removed_stopped=remove_stopwords(test)\n",
    "print(\"Removed Words: \",removed_stopped)\n",
    "p=PorterStemmer()\n",
    "stem=p.stem(removed_stopped)\n",
    "print(\"Stemmed Sentence: \",stem)\n",
    "tokenize_Sentence=tokenize(stem)\n",
    "print(\"Tokenize Sentence: \",list(tokenize_Sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7a4c8ce-d47c-41e1-87e6-967a028f2293",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_sentence(sentence):\n",
    "    p=PorterStemmer()\n",
    "    removed_stopped=remove_stopwords(sentence)\n",
    "    stem=p.stem(removed_stopped)\n",
    "    tokens=tokenize(stem)\n",
    "    return list(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c754cee3-e648-4f31-954e-7197cc3b7a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized spam:  [['to', 'use', 'credit', 'click', 'new', 'wap', 'link', 'years', 'txt', 'message', 'click'], ['thanks', 'subscription', 'new', 'ringtone', 'uk', 'new', 'mobile', 'charged', 'month', 'please', 'confirm', 'annoncement', 'repli'], ['as', 'valued', 'customer', 'i', 'pleased', 'advise', 'following', 'recent', 'delivery', 'waiting', 'review', 'mob', 'no', 'awarded', 'with', 'call', 'review'], ['please', 'new', 'customer', 'service', 'repres'], ['we', 'trying', 'contact', 'you', 'last', 'weekends', 'customer', 'draw', 'shows', 'won', 'prize', 'guaranteed', 'calling', 'year']]\n",
      "Tokenized non:   [['i', 'don', 't', 'think', 'goes', 'usf', 'l'], ['new', 'car', 'house', 'parents', 'new', 'job', 'hand'], ['great', 'escape', 'i', 'fancy', 'bridge', 'needs', 'lager', 'see', 'tomorrow'], ['tired', 'i', 'haven', 't', 'slept', 'past', 'nights'], ['too', 'late', 'i', 'said', 'website', 'i', 'didn', 't', 'dont', 'slipp'], ['i', 'come', 'tonight', 'class', 'lets', 'earli'], ['jos', 'ask', 'u', 'wana', 'meet', 'up'], ['that', 'great', 'we', 'll', 'guild', 'we', 'try', 'meeting', 'customer', 'bristol', 'road']]\n",
      "Dictionary:      {'jos', 'bridge', 'thanks', 'mob', 'shows', 'prize', 'slept', 'mobile', 'guaranteed', 'needs', 'won', 'earli', 'confirm', 'slipp', 'think', 'we', 'past', 'uk', 'click', 'class', 'haven', 'up', 'annoncement', 'nights', 'lets', 'l', 'valued', 'subscription', 'review', 'u', 'pleased', 'come', 'weekends', 'bristol', 'fancy', 'll', 'wana', 'following', 'road', 'usf', 'repres', 'advise', 'tonight', 'goes', 'house', 'escape', 'wap', 'trying', 'waiting', 'car', 'as', 'call', 'great', 'tomorrow', 'too', 'try', 'last', 'see', 'that', 'to', 'new', 'customer', 'i', 'years', 'charged', 'meeting', 'year', 'link', 'contact', 'delivery', 't', 'dont', 'lager', 'calling', 'website', 'with', 'job', 'ask', 'meet', 'parents', 'ringtone', 'don', 'guild', 'late', 'draw', 'hand', 'service', 'use', 'credit', 'txt', 'you', 'repli', 'awarded', 'didn', 'please', 'recent', 'no', 'said', 'message', 'tired', 'month'}\n"
     ]
    }
   ],
   "source": [
    "dictionary=set()\n",
    "spam_tokenize=[]\n",
    "nonspam_tokenize=[]\n",
    "\n",
    "for sentence in spam:\n",
    "    tokenized=tokenize_sentence(sentence)\n",
    "    spam_tokenize.append(tokenized)\n",
    "    dictionary  =  dictionary.union(tokenized)\n",
    "\n",
    "for sentence in non:\n",
    "    tokenized=tokenize_sentence(sentence)\n",
    "    nonspam_tokenize.append(tokenized)\n",
    "    dictionary  =  dictionary.union(tokenized)\n",
    "\n",
    "print(\"Tokenized spam: \", spam_tokenize)\n",
    "print(\"Tokenized non:  \", nonspam_tokenize)\n",
    "print(\"Dictionary:     \", dictionary)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd46ab9d-27a4-4dfe-af94-09ee9f020923",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_words=len(dictionary)\n",
    "spam_messages=len(spam_tokenize)\n",
    "total_messages=len(spam_tokenize)+len(nonspam_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28c082bb-f4ff-4888-a1df-76913500a7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_frequecy_in_message(word,message):\n",
    "    total_count=0\n",
    "    for msg in message:\n",
    "        if word in msg:\n",
    "            total_count+=1\n",
    "    return total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20623e8f-87b9-4fe6-9569-b29b6ab42077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38461538461538464"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#p(spam)\n",
    "p_spam=spam_messages/total_messages\n",
    "p_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9be7f189-f165-4151-aec7-430148358766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n",
      "Calculating probability for word:  customer\n",
      "P(spam):  0.38461538461538464\n",
      "P(w|spam):  0.6\n",
      "P(w):  0.3076923076923077\n",
      "P(spam|w):  0.75\n",
      "---------------------\n",
      "Calculating probability for word:  service\n",
      "P(spam):  0.38461538461538464\n",
      "P(w|spam):  0.2\n",
      "P(w):  0.07692307692307693\n",
      "P(spam|w):  1.0\n",
      "---------------------\n",
      "Calculating probability for word:  annoncement\n",
      "P(spam):  0.38461538461538464\n",
      "P(w|spam):  0.2\n",
      "P(w):  0.07692307692307693\n",
      "P(spam|w):  1.0\n",
      "---------------------\n",
      "Calculating probability for word:  you\n",
      "P(spam):  0.38461538461538464\n",
      "P(w|spam):  0.2\n",
      "P(w):  0.07692307692307693\n",
      "P(spam|w):  1.0\n",
      "---------------------\n",
      "Calculating probability for word:  new\n",
      "P(spam):  0.38461538461538464\n",
      "P(w|spam):  0.6\n",
      "P(w):  0.3076923076923077\n",
      "P(spam|w):  0.75\n",
      "---------------------\n",
      "Calculating probability for word:  years\n",
      "P(spam):  0.38461538461538464\n",
      "P(w|spam):  0.2\n",
      "P(w):  0.07692307692307693\n",
      "P(spam|w):  1.0\n",
      "---------------------\n",
      "Calculating probability for word:  delivery\n",
      "P(spam):  0.38461538461538464\n",
      "P(w|spam):  0.2\n",
      "P(w):  0.07692307692307693\n",
      "P(spam|w):  1.0\n",
      "---------------------\n",
      "Calculating probability for word:  waiting\n",
      "P(spam):  0.38461538461538464\n",
      "P(w|spam):  0.2\n",
      "P(w):  0.07692307692307693\n",
      "P(spam|w):  1.0\n",
      "---------------------\n",
      "Calculating probability for word:  you\n",
      "P(spam):  0.38461538461538464\n",
      "P(w|spam):  0.2\n",
      "P(w):  0.07692307692307693\n",
      "P(spam|w):  1.0\n",
      "---------------------\n",
      "Calculating probability for word:  click\n",
      "P(spam):  0.38461538461538464\n",
      "P(w|spam):  0.2\n",
      "P(w):  0.07692307692307693\n",
      "P(spam|w):  1.0\n",
      "Final Probability:  0.5625\n"
     ]
    }
   ],
   "source": [
    "final_prob=1\n",
    "for sentence in spam_test:\n",
    "    test_sentence=tokenize_sentence(sentence)\n",
    "for word in test_sentence:\n",
    "    print(\"---------------------\")\n",
    "    print(\"Calculating probability for word: \",word)\n",
    "    \n",
    "    #p(w|spam)\n",
    "    p_w_spam=word_frequecy_in_message(word,spam_tokenize)/spam_messages\n",
    "    \n",
    "    #p(w)\n",
    "    word_count = word_frequecy_in_message(word,spam_tokenize)\n",
    "    word_count += word_frequecy_in_message(word,nonspam_tokenize)\n",
    "    p_w=word_count/total_messages\n",
    "    #p(spam|word)\n",
    "    p_spam_word=(p_w_spam*p_spam)/p_w\n",
    "\n",
    "    print(\"P(spam): \",p_spam)\n",
    "    print(\"P(w|spam): \",p_w_spam)\n",
    "    print(\"P(w): \",p_w)\n",
    "    print(\"P(spam|w): \",p_spam_word)\n",
    "    final_prob *=p_spam_word\n",
    "print(\"Final Probability: \",final_prob)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
